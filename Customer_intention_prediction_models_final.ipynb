{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "The goal is to identify which features are important and influence the buying intent of customers. There are 3 sets of feature and 2 models are trained on each set. The tree based model(Gradient boosted trees) will be used to determine feature importance. The model with the highest Balanced accuracy score will be selected. The neural netwrok based mode serves as reference for how good the tree based model is. Ideally the performance between the two models should be equal. \n",
    "\n",
    "\n",
    "## Model selection\n",
    "\n",
    "The hyper parameter for each model is optimized using bayesian optimization and 5 fold  stratified Cross Validation. Each model is trained on there different transformations of the original dataset. Since the data set is imbalanced be use balanced accuracy as the metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and selection for gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import lightgbm as lgb #light gradient boosted tree\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold # train and test split\n",
    "from sklearn.metrics import balanced_accuracy_score,precision_score# metrics\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK# optimization\n",
    "import numpy as np\n",
    "import pandas as pd # reading data\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_encoded = pd.read_csv('/Users/HP/Downloads/online_shoppers_intention_encoded.csv', index_col=False)\n",
    "df_scaled = pd.read_csv('/Users/HP/Downloads/online_shoppers_intention_encoded_scaled.csv', index_col=False)\n",
    "df_transformed = pd.read_csv('/Users/HP/Downloads/online_shoppers_intention_encoded_scaled_transformed.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate label\n",
    "label = df_encoded.pop('Revenue').astype('int')\n",
    "_,_ = df_scaled.pop('Revenue'),df_transformed.pop('Revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split object for CV \n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n",
    "#Hyperparameter search space for gradient boosed trees\n",
    "lgb_space = {'lr':hp.loguniform('lr',-6.9,-2.3),'num_leaves':hp.quniform('num_leaves',15,255,1),\n",
    "         'max_depth':hp.choice('max_depth',[-1,9,12]),'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_optimizer(params):\n",
    "    '''A function to optimize  lgb classifier\n",
    "    :params:=params , dictionary containing the Hyper-parameters for the classifier\n",
    "    returns true loss and validation loss\n",
    "    '''\n",
    "    if 'num_leaves' in params:\n",
    "        params['num_leaves']=int(params['num_leaves'])\n",
    "    if 'max_depth' in params:\n",
    "        params['max_depth']=int(params['max_depth'])\n",
    "    val_score=[]\n",
    "    true_scores=[]\n",
    "    rd=1\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        clf = lgb.LGBMClassifier(n_estimators=2000,**params)\n",
    "        clf.fit(X_tr,y_tr,eval_set=(X_val,y_val),early_stopping_rounds =200,eval_metric='logloss',verbose=False)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        y_tr_pred=clf.predict(X_tr)\n",
    "        score=balanced_accuracy_score(y_val,y_pred,)\n",
    "        true_score=balanced_accuracy_score(y_tr,y_tr_pred)\n",
    "        val_score.append(score)\n",
    "        true_scores.append(true_score)\n",
    "        rd+=1\n",
    "    mean,std =np.mean(val_score),np.std(val_score)\n",
    "    true_mean=np.mean(true_scores)\n",
    "    print(\"mean: {}, Std: {}\".format(mean,std))\n",
    "    return {'loss':-mean,'status': STATUS_OK,'true_loss':-true_mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7713629479019699, Std: 0.014022656449164981                                                                    \n",
      "mean: 0.780347780500698, Std: 0.015762279238775514                                                                     \n",
      "mean: 0.7710274330388664, Std: 0.016409413555054896                                                                    \n",
      "mean: 0.771373582703389, Std: 0.022747265106522828                                                                     \n",
      "mean: 0.7248698142846253, Std: 0.015261198257772803                                                                    \n",
      "mean: 0.7630016383342728, Std: 0.012187429265890006                                                                    \n",
      "mean: 0.7879509699413774, Std: 0.010876119830070488                                                                    \n",
      "mean: 0.7831192584881587, Std: 0.014550309308066956                                                                    \n",
      "mean: 0.7856147690023656, Std: 0.01393542053617744                                                                     \n",
      "mean: 0.778366576981091, Std: 0.007413134452175299                                                                     \n",
      "mean: 0.782279115424461, Std: 0.016387784807755133                                                                     \n",
      "mean: 0.7688100457009034, Std: 0.01797000695489897                                                                     \n",
      "mean: 0.772415824484537, Std: 0.015584137918876126                                                                     \n",
      "mean: 0.7500490687987924, Std: 0.012080863039566013                                                                    \n",
      "mean: 0.7628381423213859, Std: 0.015842937800571708                                                                    \n",
      "mean: 0.7709189918058292, Std: 0.006067726307337097                                                                    \n",
      "mean: 0.7672781031813177, Std: 0.010384748461757824                                                                    \n",
      "mean: 0.7709690041152057, Std: 0.009077773321305403                                                                    \n",
      "mean: 0.7668021364578739, Std: 0.009697249423539762                                                                    \n",
      "mean: 0.7576981216016436, Std: 0.005370871720365814                                                                    \n",
      "100%|███████████████████████████████████████████████| 20/20 [03:03<00:00,  9.16s/trial, best loss: -0.7879509699413774]\n"
     ]
    }
   ],
   "source": [
    "#split into train and test and call the fmin(optimizer) function for encoded dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_encoded,label,test_size=0.2,random_state=42)\n",
    "trials_encoded = Trials()\n",
    "best_e= fmin(lgb_optimizer,lgb_space, algo=tpe.suggest, max_evals=20, trials=trials_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7787378702654202, Std: 0.01093795296107058                                                                     \n",
      "mean: 0.754637217056172, Std: 0.01431626225654564                                                                      \n",
      "mean: 0.7816760746960459, Std: 0.0074380866995027795                                                                   \n",
      "mean: 0.7526548700767182, Std: 0.01655363420291347                                                                     \n",
      "mean: 0.7555656064773564, Std: 0.013372533498388892                                                                    \n",
      "mean: 0.7734443197538624, Std: 0.015793656323519624                                                                    \n",
      "mean: 0.7750385527172481, Std: 0.012205536082764699                                                                    \n",
      "mean: 0.7718812851238999, Std: 0.008365688619768406                                                                    \n",
      "mean: 0.77190147999945, Std: 0.017268533956125223                                                                      \n",
      "mean: 0.7826877242399741, Std: 0.016050532856283613                                                                    \n",
      "mean: 0.7629529506887627, Std: 0.01726756151329856                                                                     \n",
      "mean: 0.7722612574559206, Std: 0.012171712491396789                                                                    \n",
      "mean: 0.7728780446961584, Std: 0.01210018937540461                                                                     \n",
      "mean: 0.7747729576120059, Std: 0.01784584924002597                                                                     \n",
      "mean: 0.7695872172436246, Std: 0.013104238391181766                                                                    \n",
      "mean: 0.7711354681249633, Std: 0.011707472415116741                                                                    \n",
      "mean: 0.7458839069586093, Std: 0.009975277597567474                                                                    \n",
      "mean: 0.7631295246331243, Std: 0.01601518168047124                                                                     \n",
      "mean: 0.7738562652226997, Std: 0.016522624364503972                                                                    \n",
      "mean: 0.7718612089682242, Std: 0.007373000259629666                                                                    \n",
      "100%|███████████████████████████████████████████████| 20/20 [03:09<00:00,  9.49s/trial, best loss: -0.7826877242399741]\n"
     ]
    }
   ],
   "source": [
    "#for scaled dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_scaled,label,test_size=0.2,random_state=42)\n",
    "trials_scaled = Trials()\n",
    "best_scaled = fmin(lgb_optimizer, lgb_space, algo=tpe.suggest, max_evals=20, trials=trials_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7556790901808667, Std: 0.017191758097012653                                                                    \n",
      "mean: 0.7693387302971871, Std: 0.013241904437937397                                                                    \n",
      "mean: 0.775091676737028, Std: 0.006264268835771365                                                                     \n",
      "mean: 0.7512313562933406, Std: 0.019723296194634834                                                                    \n",
      "mean: 0.7642284895207841, Std: 0.007357532261403563                                                                    \n",
      "mean: 0.7570160259334193, Std: 0.017369838286645685                                                                    \n",
      "mean: 0.7800906270033978, Std: 0.01377275678014378                                                                     \n",
      "mean: 0.7601200507871128, Std: 0.008949656580634999                                                                    \n",
      "mean: 0.768041553205874, Std: 0.013167533012010648                                                                     \n",
      "mean: 0.775401954254108, Std: 0.02004302071227557                                                                      \n",
      "mean: 0.7601795419412323, Std: 0.014321642810747418                                                                    \n",
      "mean: 0.7739588891818702, Std: 0.006963381652690117                                                                    \n",
      "mean: 0.7855711238273287, Std: 0.007199779740052417                                                                    \n",
      "mean: 0.768400518368464, Std: 0.013560537269338802                                                                     \n",
      "mean: 0.7747824364567492, Std: 0.007932909665335969                                                                    \n",
      "mean: 0.758088978671662, Std: 0.004760476947865791                                                                     \n",
      "mean: 0.7712008952728245, Std: 0.013114350446721127                                                                    \n",
      "mean: 0.7557512281258629, Std: 0.008156622819357941                                                                    \n",
      "mean: 0.766531905029099, Std: 0.01378426749134896                                                                      \n",
      "mean: 0.7586577093562508, Std: 0.01052890634621811                                                                     \n",
      "100%|███████████████████████████████████████████████| 20/20 [03:03<00:00,  9.16s/trial, best loss: -0.7855711238273287]\n"
     ]
    }
   ],
   "source": [
    "#for transformed dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_transformed,label,test_size=0.2,random_state=42)\n",
    "trials_transformed = Trials()\n",
    "best_transformed = fmin(lgb_optimizer, lgb_space, algo=tpe.suggest, max_evals=20, trials=trials_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(Data,label,params,classifier='lgb',test_size=0.2):\n",
    "    '''A function to train a model. \n",
    "    parameters:\n",
    "    Data :=pandas dataset or numpy array of features\n",
    "    label:=pandas dataset or numpy array of labels for features \n",
    "    params:=python dict parametes for the model\n",
    "    model:=keras model object or sklearn classifier object\n",
    "    test_size:=Float (0,1) fraction for test split\n",
    "    return\n",
    "    model:=str 'keras','lgb'\n",
    "    train_score:=float balanced accuracy train score\n",
    "    test_score:=float balanced accuracy test score\n",
    "    returns-trained model,train_score,test_score\n",
    "    '''\n",
    "    X_train,X_test,y_train,y_test = train_test_split(Data,label,test_size=test_size,random_state=42)\n",
    "    if classifier=='lgb':\n",
    "        if 'num_leaves' in params:\n",
    "            params['num_leaves']=int(params['num_leaves'])\n",
    "        if 'max_depth' in params:\n",
    "            #max_depth=[-1,9,12]#max_depth choice list\n",
    "            params['max_depth']=-1#int(params['max_depth'])#best returns an index corresponding the choice\n",
    "        clf = lgb.LGBMClassifier(n_estimators=5000,**params)\n",
    "        clf.fit(X_train,y_train,eval_set=(X_test,y_test),early_stopping_rounds =200,eval_metric='auc',verbose=False)\n",
    "        train_pred=clf.predict(X_train)\n",
    "        test_pred=clf.predict(X_test)\n",
    "    elif classifier=='keras':\n",
    "        opt=['adam','sgd']\n",
    "        if 'optimizer' in params:\n",
    "            params['optimizer'] =opt[params['optimizer']]\n",
    "        clf = model(feature_size=X_train.shape[-1],**params)\n",
    "        clf.fit(X_train,y_train,epochs=20,batch_size=128,verbose=0)\n",
    "        train_pred=np.round(clf.predict(X_train))\n",
    "        test_pred=np.round(clf.predict(X_test))\n",
    "    train_score = balanced_accuracy_score(train_pred,y_train)\n",
    "    test_score= balanced_accuracy_score(test_pred,y_test)\n",
    "    return clf,train_score,test_score\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.4689966115050747, 'lr': 0.004186154212450494, 'max_depth': 2, 'num_leaves': 19.0}\n",
      "{'colsample_bytree': 0.7188856959407939, 'lr': 0.0050239777912343825, 'max_depth': 2, 'num_leaves': 40.0}\n",
      "{'colsample_bytree': 0.8825849809832234, 'lr': 0.05750543680313465, 'max_depth': 2, 'num_leaves': 16.0}\n"
     ]
    }
   ],
   "source": [
    "print(best_e)\n",
    "print(best_scaled)\n",
    "print(best_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_encoded,lgb_train_encoded,lgb_test_encoded=model_trainer(df_encoded,label,best_e)\n",
    "clf_scaled,lgb_train_scaled,lgb_test_scaled=model_trainer(df_scaled,label,best_scaled)\n",
    "clf_transformed,lgb_train_transformed,lgb_test_transformed=model_trainer(df_transformed,label,best_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "| Dataset Type | Train Score | Test Score |\n",
      "| Encoded      | 0.894319       | 0.811391     |\n",
      "| Scaled       | 0.909196       | 0.845628     |\n",
      "| Transformed  | 0.909196       | 0.845628     |\n"
     ]
    }
   ],
   "source": [
    "print(\"results\")\n",
    "print(\"| Dataset Type | Train Score | Test Score |\")\n",
    "print(\"| Encoded      | {:2f}       | {:2f}     |\".format(lgb_train_encoded,lgb_test_encoded))\n",
    "print(\"| Scaled       | {:2f}       | {:2f}     |\".format(lgb_train_scaled,lgb_test_scaled))\n",
    "print(\"| Transformed  | {:2f}       | {:2f}     |\".format(lgb_train_scaled,lgb_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimization and selection for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature_size,lr=0.1,optimizer='adam',hl_size=128):\n",
    "    ''' function to define keras model\n",
    "    :feature:=\n",
    "    '''\n",
    "    if optimizer=='adam':\n",
    "        opt =Adam(lr=lr)\n",
    "    elif optimizer=='sgd':\n",
    "        opt = SGD(lr=lr)\n",
    "    hl_size=int(hl_size)\n",
    "    model =Sequential()\n",
    "    model.add(Dense(hl_size,activation='relu',input_shape=(feature_size,)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(hl_size,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_optimizer(params):\n",
    "    val_score=[]\n",
    "    true_scores=[]\n",
    "    rd=1\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        nn_model = model(X_train.shape[1],**params)\n",
    "        cb = EarlyStopping(monitor='val_acc',min_delta=0.001,patience=3)\n",
    "        nn_model.fit(X_tr,y_tr,validation_data=(X_val,y_val),batch_size=128,callbacks=[cb],epochs=50,verbose=0)\n",
    "        #_,score= nn_model.evaluate(X_val,y_val)\n",
    "        #_,true_score=nn_model.evaluate(X_tr,y_tr)\n",
    "        cv_pred = np.round(nn_model.predict(X_val))\n",
    "        score=balanced_accuracy_score(y_val,cv_pred)\n",
    "        y_tr_pred = np.round(nn_model.predict(X_tr))\n",
    "        true_score=balanced_accuracy_score(y_tr,y_tr_pred)\n",
    "        \n",
    "        val_score.append(score)\n",
    "        true_scores.append(true_score)\n",
    "        rd+=1\n",
    "    mean,std =np.mean(val_score),np.std(val_score)\n",
    "    true_mean=np.mean(true_scores)\n",
    "    print(\"mean: {}, Std: {}\".format(mean,std))\n",
    "    return {'loss':-mean,'status': STATUS_OK,'true_loss':-true_mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_space = {'lr':hp.loguniform('lr',-10,-2.3),'optimizer':hp.choice('optimizer',['adam','sgd'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7086648325487408, Std: 0.07723872840502996                                                                     \n",
      "mean: 0.6171397695334809, Std: 0.04880126245239854                                                                     \n",
      "mean: 0.5454720677128179, Std: 0.0729035793995225                                                                      \n",
      "mean: 0.5799615472573834, Std: 0.03360333448674164                                                                     \n",
      "mean: 0.5009075009716284, Std: 0.001186335657067173                                                                    \n",
      "mean: 0.5004847769878393, Std: 0.001178616909500873                                                                    \n",
      "mean: 0.6623623880440338, Std: 0.0697524958173388                                                                      \n",
      "mean: 0.6592444417229129, Std: 0.06523394754834763                                                                     \n",
      "mean: 0.5988328961526014, Std: 0.01362868076363621                                                                     \n",
      "mean: 0.5055332146967707, Std: 0.008892574707972861                                                                    \n",
      "100%|███████████████████████████████████████████████| 10/10 [08:33<00:00, 51.40s/trial, best loss: -0.7086648325487408]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df_encoded,label,test_size=0.2,random_state=42)\n",
    "best_nn_encoded=fmin(keras_optimizer,keras_space,algo=tpe.suggest,max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.7219638704178815, Std: 0.021954436950303195                                                                    \n",
      "mean: 0.7354628887919691, Std: 0.013861708043929562                                                                    \n",
      "mean: 0.501937033477755, Std: 0.0026214705544049923                                                                    \n",
      "mean: 0.7171683185391707, Std: 0.026080430368878662                                                                    \n",
      "mean: 0.7273322894315568, Std: 0.01796457474690111                                                                     \n",
      "mean: 0.5021870700309796, Std: 0.00423234901273516                                                                     \n",
      "mean: 0.5, Std: 0.0                                                                                                    \n",
      "mean: 0.7375225973909121, Std: 0.014545876306617859                                                                    \n",
      "mean: 0.5, Std: 0.0                                                                                                    \n",
      "mean: 0.5, Std: 0.0                                                                                                    \n",
      "100%|██████████████████████████████████████████████| 10/10 [24:17<00:00, 145.77s/trial, best loss: -0.7375225973909121]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df_scaled,label,test_size=0.2,random_state=42)\n",
    "best_nn_scaled=fmin(keras_optimizer,keras_space,algo=tpe.suggest,max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5010472842516212, Std: 0.001413357299691906                                                                    \n",
      "mean: 0.7747693585252742, Std: 0.011767663859868202                                                                    \n",
      "mean: 0.7774581574925363, Std: 0.017763871163451114                                                                    \n",
      "mean: 0.5104811279137919, Std: 0.0035720522366064567                                                                   \n",
      "mean: 0.5060905357765467, Std: 0.012332225726712694                                                                    \n",
      "mean: 0.5, Std: 0.0                                                                                                    \n",
      "mean: 0.794206551337598, Std: 0.015221384021555906                                                                     \n",
      "mean: 0.5, Std: 0.0                                                                                                    \n",
      "mean: 0.501289285343844, Std: 0.0012067107918905498                                                                    \n",
      "mean: 0.7914077615305116, Std: 0.010733455198098433                                                                    \n",
      "100%|███████████████████████████████████████████████| 10/10 [34:07<00:00, 204.79s/trial, best loss: -0.794206551337598]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df_transformed,label,test_size=0.2,random_state=42)\n",
    "best_nn_transformed=fmin(keras_optimizer,keras_space,algo=tpe.suggest,max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.0007622296280598096, 'optimizer': 0}\n",
      "{'lr': 0.015542263054046233, 'optimizer': 0}\n",
      "{'lr': 0.009366074941875552, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "print(best_nn_encoded)\n",
    "print(best_nn_scaled)\n",
    "print(best_nn_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,nn_train_encoded,nn_test_encoded=model_trainer(df_encoded,label,best_nn_encoded,'keras')\n",
    "_,nn_train_scaled,nn_test_scaled=model_trainer(df_scaled,label,best_nn_scaled,'keras')\n",
    "_,nn_train_transformed,nn_test_transformed=model_trainer(df_transformed,label,best_nn_transformed,'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|              |        neural network            |       Boosted Trees       |\n",
      "| Dataset Type | Train Score     | Test Score     |Train Score   | Test Score |\n",
      "| Encoded      | 0.7690          | 0.7374         | 0.8943       | 0.8114     |\n",
      "| Scaled       | 0.8696          | 0.7937         | 0.9092       | 0.8456     |\n",
      "| Transformed  | 0.8696          | 0.7937         | 0.9092       | 0.8456     |\n"
     ]
    }
   ],
   "source": [
    "print(\"|              |        neural network            |       Boosted Trees       |\")\n",
    "print(\"| Dataset Type | Train Score     | Test Score     |Train Score   | Test Score |\")\n",
    "print(\"| Encoded      | {:.4f}          | {:.4f}         | {:.4f}       | {:.4f}     |\".format(nn_train_encoded,nn_test_encoded,lgb_train_encoded,lgb_test_encoded))\n",
    "print(\"| Scaled       | {:.4f}          | {:.4f}         | {:.4f}       | {:.4f}     |\".format(nn_train_scaled,nn_test_scaled,lgb_train_scaled,lgb_test_scaled))\n",
    "print(\"| Transformed  | {:.4f}          | {:.4f}         | {:.4f}       | {:.4f}     |\".format(nn_train_scaled,nn_test_scaled,lgb_train_scaled,lgb_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result for both tree based model and neural network model are obtained on the feature set that is not scaled or transfromed. Both models perform equally well with the neural netwrok performing 1 percent better than the gradient boosted trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb_best.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf_encoded, 'lgb_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature importance for the best tree based model\n",
    "%matplotlib inline\n",
    "lgb.plot_importance(clf_encoded,max_num_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The top 10 features affecting the buying intentions were identified. These features can be further isolated depending upon the applications. For eg. Exit would be a good measure of how well personalized webpages are working for users. A simple A/B test can be carried out with and without personalization and exit rates as well as other features can be monitored. Change in these features would indicate a change in buying intent and tell us if the test was succesfull. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
